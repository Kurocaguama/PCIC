{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c647374-d884-4c31-93ae-9d9208bb4312",
   "metadata": {},
   "source": [
    "# Ej1: Clasificación de rostros: ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a965f19-9ce6-42df-beb3-cd4bbdda7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cabrones ya no quiero hacer tarea me lleva"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26df4505-54b1-4c87-aa97-5cda438fe007",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Ej2: Reconocimiento de comandos de voz\n",
    "\n",
    "La importación de datos se hace basándonos en el notebook oficial del curso [(Github de Gibrán)](https://github.com/gibranfp/CursoAprendizajeProfundo/blob/2026-1/notebooks/1d_procesamiento_audio.ipynb). La red ya es una implementación personal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f458f-403c-4c0e-b70c-3720cd8bf437",
   "metadata": {},
   "source": [
    "## 2.1 Datos, Dataset, y Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fdb8880-c5d3-42c5-853e-8bf8c67ce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import librosa\n",
    "import IPython as ip\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "from tqdm.auto import trange\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78c3bcfb-43d7-4830-8815-f83a3e42964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_ds = SPEECHCOMMANDS(r'C:\\Users\\FLopezP\\Desktop\\PCIC\\Tercer Semestre\\Datasets', download = False) # download = True solo si no lo predescargaste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51211df5-82ff-41dc-8d3a-bd0e9d62983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'backward': 0, 'bed': 1, 'bird': 2, 'cat': 3, 'dog': 4, 'down': 5, 'eight': 6, 'five': 7, 'follow': 8, 'forward': 9, 'four': 10, 'go': 11, 'happy': 12, 'house': 13, 'learn': 14, 'left': 15, 'marvin': 16, 'nine': 17, 'no': 18, 'off': 19, 'on': 20, 'one': 21, 'right': 22, 'seven': 23, 'sheila': 24, 'six': 25, 'stop': 26, 'three': 27, 'tree': 28, 'two': 29, 'up': 30, 'visual': 31, 'wow': 32, 'yes': 33, 'zero': 34}\n"
     ]
    }
   ],
   "source": [
    "CLASSES = (\n",
    "    'backward', 'bed', 'bird', 'cat', 'dog',\n",
    "    'down', 'eight', 'five', 'follow', 'forward',\n",
    "    'four', 'go', 'happy', 'house', 'learn',\n",
    "    'left', 'marvin', 'nine', 'no', 'off',\n",
    "    'on', 'one', 'right', 'seven', 'sheila',\n",
    "    'six', 'stop', 'three', 'tree', 'two',\n",
    "    'up', 'visual', 'wow', 'yes', 'zero'\n",
    ")\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "CLASS_IDX = {c: i for i, c in enumerate(CLASSES)}\n",
    "print(CLASS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac7ddfbd-af89-4c78-a628-bcb9aaa6f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros. (Extraídos del notebook)\n",
    "BATCH_SIZE = 32\n",
    "SECS = 1\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 400\n",
    "HOP_LENGTH = N_FFT // 2\n",
    "\n",
    "class MySpeechCommands(SPEECHCOMMANDS):\n",
    "    \"\"\"\n",
    "    Clase para crear el dataloader. (Extraída del notebook)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "               root, \n",
    "               download = False, \n",
    "               subset = None,\n",
    "               waveform_tsfm = None, \n",
    "               label_tsfm = None):\n",
    "        super().__init__(root = root, download = download, subset = subset)\n",
    "        self.waveform_tsfm = waveform_tsfm\n",
    "        self.label_tsfm = label_tsfm\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        waveform, sample_rate, label, *_ = super().__getitem__(i)\n",
    "    \n",
    "        if self.waveform_tsfm:\n",
    "            x = self.waveform_tsfm(waveform)\n",
    "        \n",
    "        if self.label_tsfm:\n",
    "            y = self.label_tsfm(label)\n",
    "          \n",
    "        return x, y, label, sample_rate\n",
    "      \n",
    "class WaveformPadTruncate(nn.Module):\n",
    "    \"\"\"\n",
    "    Clase para crear el dataloader. (Extraída del notebook)\n",
    "    \"\"\"\n",
    "    def __init__(self, secs = SECS, sample_rate = SAMPLE_RATE):\n",
    "        super().__init__()\n",
    "        self.samples = secs * sample_rate\n",
    "    \n",
    "    def forward(self, waveform):\n",
    "        samples = waveform.shape[1]\n",
    "    \n",
    "        if samples < self.samples:\n",
    "            difference = self.samples - samples\n",
    "            padding = th.zeros(1, difference)\n",
    "            waveform = th.cat([waveform, padding], 1)\n",
    "        \n",
    "        elif samples > self.samples:\n",
    "            start = random.randint(0, waveform.shape[1] - self.samples)\n",
    "            # Devuelve un nuevo tensor que es una versión reducida del tensor de entrada.\n",
    "            waveform = waveform.narrow(1, start, self.samples) # (dimension, start, length)\n",
    "            \n",
    "        return waveform\n",
    "\n",
    "def label2index(label):\n",
    "    return CLASS_IDX[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfcc41e9-fe47-45e9-96a6-05c9cf2385bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del dataset y dataloader.\n",
    "ds = MySpeechCommands(\n",
    "  root = r'C:\\Users\\FLopezP\\Desktop\\PCIC\\Tercer Semestre\\Datasets',\n",
    "  waveform_tsfm = WaveformPadTruncate(),\n",
    "  label_tsfm = label2index,\n",
    ")\n",
    "\n",
    "# creamos un DataLoader\n",
    "dl = DataLoader(\n",
    "  ds,\n",
    "  batch_size = BATCH_SIZE,\n",
    "  shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602a39c7-d374-40d2-b8ea-36f20d858e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape = torch.Size([32, 1, 16000]) dtype = torch.float32\n",
      "y shape = torch.Size([32]) dtype = torch.int64\n",
      "label = ('one', 'seven', 'eight', 'go', 'no', 'wow', 'backward', 'visual', 'up', 'no', 'nine', 'one', 'down', 'four', 'up', 'marvin', 'zero', 'backward', 'bird', 'off', 'seven', 'happy', 'visual', 'no', 'go', 'no', 'backward', 'tree', 'two', 'eight', 'left', 'learn') type = <class 'tuple'>\n",
      "sr tensor shape = torch.Size([32]) type = <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "x, y, label, sr = next(iter(dl))\n",
    "print(f'x shape = {x.shape} dtype = {x.dtype}')\n",
    "print(f'y shape = {y.shape} dtype = {y.dtype}')\n",
    "print(f'label = {label} type = {type(label)}')\n",
    "print(f'sr tensor shape = {sr.shape} type = {type(sr)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6fea58-0667-442e-ba76-9016fa789754",
   "metadata": {},
   "source": [
    "## 2.2 Red Neuronal basada en Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "390cfd70-dd2b-4bc4-b523-0fd0e1dd7487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FLopezP\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedNeuronal(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (enc_layer): TransformerEncoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=16000, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=16000, bias=True)\n",
      "    (norm1): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (dec_layer): TransformerDecoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      "    )\n",
      "    (multihead_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=16000, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=16000, bias=True)\n",
      "    (norm1): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (dropout3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (proc1): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=16000, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=16000, bias=True)\n",
      "        (norm1): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proc2): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=16000, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=16000, bias=True)\n",
      "        (norm1): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((16000,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classification): Linear(in_features=16000, out_features=35, bias=True)\n",
      ")\n",
      "CPU times: total: 1min 31s\n",
      "Wall time: 41 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        La red consta de un bloque transformer con 2 bloques de: 4 Encoders y 2 Decoders. (Se usan estas cantidades debido a restricciones de cómputo)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.enc_layer = nn.TransformerEncoderLayer(d_model = 16000, nhead = 4)\n",
    "        self.dec_layer = nn.TransformerDecoderLayer(d_model = 16000, nhead = 2)\n",
    "        self.proc1 = nn.TransformerEncoder(self.enc_layer, num_layers = 1)\n",
    "        self.proc2 = nn.TransformerDecoder(self.dec_layer, num_layers = 1)\n",
    "        self.classification = nn.Linear(16000, NUM_CLASSES)\n",
    "        #self.softmax = nn.Softmax(dim = 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        enc = self.proc1(x)\n",
    "        dec = self.proc2(enc,enc)\n",
    "        logits = self.classification(dec)\n",
    "        return logits\n",
    "\n",
    "red_cabrona = RedNeuronal()\n",
    "actual_logits = red_cabrona(x) # Ejecutamos una sola pasada\n",
    "pred_proba = nn.Softmax(dim=1)(actual_logits)\n",
    "y_pred = pred_proba.argmax(1)\n",
    "print(red_cabrona)\n",
    "print(\"Clase predicha: {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a53de9cd-f8ca-4f67-83d3-41423f40c9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      ") MultiheadAttention(\n",
      "  (out_proj): NonDynamicallyQuantizableLinear(in_features=16000, out_features=16000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Para encontrar los mappings hay que llegar a esto.\n",
    "print(red_cabrona.enc_layer.self_attn, red_cabrona.proc2.layers[1].self_attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f294b23-abe7-46fe-bb25-70bd7f80511a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, lf, optimizer):\n",
    "    \"\"\"\n",
    "    Loop genérico de entrenamiento. (Siguiendo: https://docs.pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation)\n",
    "    dataloader -> Pues un dataloader pa\n",
    "    model -> RedNeuronal()\n",
    "    lf -> Loss Function\n",
    "    optimizer -> Pues un optimizer bb\n",
    "    \"\"\"\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch(X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = lf(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * BATCH_SIZE + len(X)\n",
    "            print(\"Loss: {}. [{}/{}]\".format(round(loss, 4), current, size))\n",
    "\n",
    "def test_loop(dataloader, model, lf):\n",
    "    \"\"\"\n",
    "    Loop genérico de entrenamiento. (Siguiendo: https://docs.pytorch.org/tutorials/beginner/basics/optimization_tutorial.html#full-implementation)\n",
    "    dataloader -> Pues un dataloader pa\n",
    "    model -> RedNeuronal()\n",
    "    lf -> Loss Function\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += lf(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f8e23-1e9f-4fcd-9dd5-0b1737f0f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.003\n",
    "epochs = 3\n",
    "loss_fun = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "for _ in range(epochs):\n",
    "    print(\"------Epoch: {}------\".format(_+1))\n",
    "    train_loop(dl, red_cabrona, loss_fun, optim)\n",
    "print('Acabamos papito.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22588019-7287-4cb5-864e-9d5b56f8f128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya con esto podemos aplicar lo de https://colab.research.google.com/drive/1yDuwH_5HIAHLMwb2borfl_ewuGArJFco?usp=sharing#scrollTo=pqNNKRzkb2lm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7030204-d6b8-4d49-8f0a-5c0de1fb7cb8",
   "metadata": {},
   "source": [
    "# Ej3: Generación de rostros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66228142-e0c1-438c-ab31-a6ac3dc503a8",
   "metadata": {},
   "source": [
    "# Extra: Generación de texto\n",
    "\n",
    "La base del código corresponde a la implementación realizada en el notebook oficial del curso [(Github de Gibrán)](https://github.com/gibranfp/CursoAprendizajeProfundo/blob/2026-1/notebooks/4a_gpt.ipynb), que a su vez está basado en el modelo NanoGPT. La importación de datos, al ser de un conjunto de datos distinto, es realizada de manera personal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a822cd-3c20-49c4-928f-f0bfff3a6a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "import copy\n",
    "from itertools import islice\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torchmetrics.text import Perplexity\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "LR = 1e-3 # tasa de aprendizaje\n",
    "WD = 1e-4 # weight decay\n",
    "D_EMBED = 64 # tamaño de los embeddings\n",
    "D_RDP = 4 * D_EMBED # tamaño de capa oculta de red hacia adelante por posición\n",
    "N_CABEZAS = 4  # número de cabezas de autoatención\n",
    "N_CAPAS = 4 # número de bloques Transformers\n",
    "P_DROPOUT = 0.2 # Probabilidad de dropout\n",
    "\n",
    "T_CONTEXTO = 32 # tamaño del contexto\n",
    "MAXSEC = 2000 # tamaño máximo de secuencia ←en generación\n",
    "\n",
    "T_LOTE = 128\n",
    "N_EPOCAS = 30\n",
    "LOGDIR = './logs/'\n",
    "DC = 'cuda:0' if th.cuda.is_available() else 'cpu'\n",
    "\n",
    "th.manual_seed(22)\n",
    "np.random.seed(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823327b-ab53-49c1-82de-583b5c53a90c",
   "metadata": {},
   "source": [
    "## Extra.1: Importación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01c745-cb0b-4fdc-83d2-474baf71b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class SpanishDS(Dataset):\n",
    "    \"\"\"\n",
    "    Similar a la clase TinyShakespeare, pero ajustada al conjunto de datos que necesitamos.\n",
    "    \"\"\"\n",
    "    def __init__(self, context_size, path):\n",
    "        self.path = # AQUÍ VA LA RUTA LOCAL AL DATASET\n",
    "        self.context_size = context_size\n",
    "        with open(self.path, 'r', encoding = 'utf-8') as f:\n",
    "            self.text = f.read()\n",
    "\n",
    "        self.voc = Counter([c for c in self.text])\n",
    "        self.voc_size = len(self.voc)\n",
    "\n",
    "        self.i2c = {i:c for i,(c,f) in enumerate(self.voc.most_common())}\n",
    "        self.c2i = {c:i for i,(c,f) in enumerate(self.voc.most_common())}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
