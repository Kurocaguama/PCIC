{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d8a2ab-d67b-4562-a12c-45b6860809c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re, spacy, nltk\n",
    "import pandas as pd\n",
    "ramotxt = open(r'C:\\Users\\FLopezP\\Documents\\GitHub\\PCIC\\Minería de Textos\\Archivos txt\\elramoazul.txt', encoding=\"utf8\")\n",
    "ramoaux = ramotxt.readlines()\n",
    "nlp = spacy.load(\"es_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c8e5882-0952-4194-b836-0b748804a14e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ramo = [re.sub('[\\\\n\\-–¿?,.\":¡!]+', '', _) for _ in ramoaux]\n",
    "ramo = [_.lower() for _ in ramo]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cff40-947f-4a17-84fb-1a07b7150dde",
   "metadata": {},
   "source": [
    "## Palabras diferentes y lematización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abe6c74-8fdb-4a16-9e43-aed5ef1370c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lista_completa(texto, lemma):\n",
    "    \"\"\"\n",
    "    Regresa la cantidad de palabras distintas y la lista procesada.\n",
    "    \n",
    "    texto = list ; Texto a procesar, corresponde a la lista ramo.\n",
    "    lema == bool ; Determina si se hace el proceso de lematización.\n",
    "    \"\"\"\n",
    "    lista = []\n",
    "    if lemma == True:\n",
    "        for _ in texto:\n",
    "            doc = nlp(_)\n",
    "            aux = \" \".join([token.lemma_ for token in doc])\n",
    "            lista.append(aux)\n",
    "        lista = [_.split(' ') for _ in lista]\n",
    "    else:\n",
    "        lista = [_.split(' ') for _ in texto]\n",
    "\n",
    "    for _ in lista:\n",
    "        if len(_) == 1 and _[0] =='':\n",
    "            _.remove(_[0])\n",
    "\n",
    "    palabras_totales = 0\n",
    "    for _ in lista:\n",
    "        palabras_totales += len(_)\n",
    "\n",
    "    return palabras_totales, lista\n",
    "\n",
    "def set_palabras(lista):\n",
    "    \"\"\"\n",
    "    Regresa la cantidad de palabras distintas.\n",
    "\n",
    "    lista = list ; Correspondiente a un valor lista_completa(x, y)[1]\n",
    "    \"\"\"\n",
    "    lista_palabras = []\n",
    "    for _ in lista:\n",
    "        for j in _:\n",
    "            lista_palabras.append(j)\n",
    "\n",
    "    lista_set = set(lista_palabras)\n",
    "    return len(lista_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3370168-6dee-4296-bfdb-6430e080d113",
   "metadata": {},
   "source": [
    "### Ejemplo de ejecución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fcc71e-36c9-4688-b6ed-31701b2c801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_totales, p_totales_lista = lista_completa(ramo, False)\n",
    "set_ptotales = set_palabras(p_totales_lista)\n",
    "diversidad = set_ptotales/p_totales\n",
    "\n",
    "lemma_totales, lemma_totales_lista = lista_completa(ramo, True)\n",
    "set_lemma = set_palabras(lemma_totales_lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "244f834d-7ada-4057-8b66-4691f2b7e08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras totales: 827. Palabras diferentes: 436. Palabras lematizadas diferentes: 386. Diversidad léxica: 0.5272067714631197\n"
     ]
    }
   ],
   "source": [
    "print(f\"Palabras totales: {p_totales}. Palabras diferentes: {set_ptotales}. Palabras lematizadas diferentes: {set_lemma}. Diversidad léxica: {diversidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5847e-d9f4-4c0d-b3f6-306079f63555",
   "metadata": {},
   "source": [
    "## 20 Palabras frecuentes, promedios y frecuencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aac80794-2b34-49a4-ac96-6fa67d47f755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "palabras\n",
       "de          37\n",
       "la          36\n",
       "me          24\n",
       "el          22\n",
       "y           20\n",
       "no          20\n",
       "los         16\n",
       "un          16\n",
       "a           14\n",
       "ojos        13\n",
       "una         11\n",
       "con         11\n",
       "se          10\n",
       "que         10\n",
       "al           9\n",
       "mis          8\n",
       "en           7\n",
       "las          7\n",
       "señor        6\n",
       "del          6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_lista = []\n",
    "for _ in p_totales_lista:\n",
    "    for j in _:\n",
    "        dataset_lista.append(j)\n",
    "\n",
    "df = pd.DataFrame({'palabras': dataset_lista})\n",
    "freq = df.value_counts()\n",
    "freq[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e702f96e-ba31-496e-8ecc-3b038426ac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promedio de longitud por oraciones\n",
    "ramo_oraciones = ramoaux[2:]\n",
    "ramo_oraciones = [re.sub('[\\\\n]', '', _) for _ in ramo_oraciones]\n",
    "ramo_oraciones = [_ for _ in ramo_oraciones if len(_) != 0]\n",
    "\n",
    "oraciones = ''\n",
    "for _ in ramo_oraciones:\n",
    "    oraciones = oraciones + ' ' + _\n",
    "    \n",
    "sentences = nltk.sent_tokenize(oraciones)\n",
    "\n",
    "# ----------------\n",
    "\n",
    "words_per_sent = 0\n",
    "for _ in sentences:\n",
    "    aux = _.split(' ')\n",
    "    words_per_sent += len(aux)\n",
    "\n",
    "# ----------------\n",
    "\n",
    "verbs = 0\n",
    "adj = 0\n",
    "susts = 0\n",
    "for _ in sentences:\n",
    "    doc = nlp(_)\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\" or token.pos_ == \"PNOUN\":\n",
    "            susts += 1\n",
    "        if token.pos_ == \"VERB\":\n",
    "            verbs += 1\n",
    "        if token.pos_ == \"ADJ\":\n",
    "            adj += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086d0cbb-595c-4ab2-9fd4-465d2bf93e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio por oración: 7.809523809523809. Promedio distinto: 7.876190476190477.\n",
      "Palabras sin filtro: 820. Palabras con filtro: 827\n",
      "-------\n",
      "Cantidades totales.\n",
      "Verbos: 131. Adjetivos: 64. Sustantivos: 173.\n",
      "Frecuencia.\n",
      "Verbos:0.1597560975609756. Adjetivos: 0.07804878048780488. Sustantivos: 0.21097560975609755.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Promedio por oración: {words_per_sent/len(sentences)}. Promedio distinto: {p_totales/len(sentences)}.\")\n",
    "print(f\"Palabras sin filtro: {words_per_sent}. Palabras con filtro: {p_totales}\")\n",
    "print(\"-------\")\n",
    "print(\"Cantidades totales.\")\n",
    "print(f\"Verbos: {verbs}. Adjetivos: {adj}. Sustantivos: {susts}.\")\n",
    "print(\"Frecuencia.\")\n",
    "print(f\"Verbos:{verbs/words_per_sent}. Adjetivos: {adj/words_per_sent}. Sustantivos: {susts/words_per_sent}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6729276-1785-43fc-9c11-20488029f1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
