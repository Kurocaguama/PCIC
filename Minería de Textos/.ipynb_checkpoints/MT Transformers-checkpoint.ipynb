{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3ceac2-286b-45e6-ada1-5e7174e01272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>texto</th>\n",
       "      <th>pais</th>\n",
       "      <th>etiqueta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>770809220291760128</td>\n",
       "      <td>Quiero que alguien me diga cosas bonitas</td>\n",
       "      <td>ES</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>772825676793589760</td>\n",
       "      <td>@RavlRVara ¡Síguenos porfa! Tenemos que decirt...</td>\n",
       "      <td>ES</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>772508582923337729</td>\n",
       "      <td>@Charlywayty @Karim0931 cualquiera diría que e...</td>\n",
       "      <td>ES</td>\n",
       "      <td>NEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>790657169876193281</td>\n",
       "      <td>a to esto, el tio de ono no ha venio</td>\n",
       "      <td>ES</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>770967255773507584</td>\n",
       "      <td>@IKEASpain es el mismo así que tomo nota de to...</td>\n",
       "      <td>ES</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              texto pais  \\\n",
       "0  770809220291760128          Quiero que alguien me diga cosas bonitas    ES   \n",
       "1  772825676793589760  @RavlRVara ¡Síguenos porfa! Tenemos que decirt...   ES   \n",
       "2  772508582923337729  @Charlywayty @Karim0931 cualquiera diría que e...   ES   \n",
       "3  790657169876193281              a to esto, el tio de ono no ha venio    ES   \n",
       "4  770967255773507584  @IKEASpain es el mismo así que tomo nota de to...   ES   \n",
       "\n",
       "  etiqueta  \n",
       "0        N  \n",
       "1      NEU  \n",
       "2      NEU  \n",
       "3        N  \n",
       "4        P  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers, re, datasets, torch, evaluate\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "f1 = evaluate.load('f1')\n",
    "dataset = pd.read_csv(r'C:\\Users\\FLopezP\\Desktop\\PCIC\\Segundo Semestre\\Minería de textos\\Corpus TASS\\corpusTASS-2020\\test.tsv', sep = '\\t')\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2394fa9f-410e-424e-94ee-9a20ba0c5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_arrobas(tweet):\n",
    "    return re.sub(\"@+([a-zA-Z|0-9])+ | #+[a-zA-Z|0-9]\", '', tweet)\n",
    "\n",
    "def create_dataset(texto, tag, clean):\n",
    "    \"\"\"\n",
    "    texto = list ; Conjunto de tweets\n",
    "    tag = list ; Conjunto de etiquetas\n",
    "    clean = bool ; Opción de preprocesamiento\n",
    "    \"\"\"\n",
    "    if clean:\n",
    "        texto = [no_arrobas(_) for _ in texto]\n",
    "    dict_dataset = {'Tweets': texto, 'Tags': tag}\n",
    "    aux_df = pd.DataFrame(dict_dataset)\n",
    "    return Dataset.from_pandas(aux_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da31a39f-4427-4774-ae08-93c6109d0a9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Tweets', 'Tags'],\n",
       "    num_rows: 7264\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_limpio = create_dataset(dataset['texto'], dataset['etiqueta'], True)\n",
    "ds_normal = create_dataset(dataset['texto'], dataset['etiqueta'], False)\n",
    "ds_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e20eeac-e689-4508-9dd5-c3b2eb697730",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"finiteautomata/beto-sentiment-analysis\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"finiteautomata/beto-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12aaf09d-b28c-4c00-90ba-59fec10fc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_example(tweet):\n",
    "    \"\"\"\n",
    "    Evaluación manual multiclase \n",
    "\n",
    "    tweet = str ;  Texto a clasificar\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(tweet, return_tensors = 'pt')\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        logits = torch.sigmoid(logits)\n",
    "\n",
    "    value = logits[0]\n",
    "    aux = 0\n",
    "    classifier = -1\n",
    "    for _ in value:\n",
    "        if _.item() > aux:\n",
    "            aux = _\n",
    "            classifier += 1\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd6bbdf-0e9c-4ad1-9cd6-619a97504aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7264 7264\n",
      "CPU times: total: 25min 38s\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "labels = ds_limpio['Tags']\n",
    "pred_limpio = [evaluate_example(_) for _ in ds_limpio['Tweets']]\n",
    "pred_normal = [evaluate_example(_) for _ in ds_normal['Tweets']]\n",
    "print(len(pred_limpio), len(pred_normal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49483403-19f4-4ec7-a057-f815e7b3d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_and_eval(etiquetas, predicciones):\n",
    "    new_labels = []\n",
    "    for _ in etiquetas:\n",
    "        if str(_) == 'P':\n",
    "            new_labels.append(2)\n",
    "        elif str(_) == 'N':\n",
    "            new_labels.append(0)\n",
    "        else:\n",
    "            new_labels.append(1)\n",
    "    results = f1.compute(references = new_labels, predictions = predicciones, average = 'macro')\n",
    "    return results, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8e295a-8a79-425c-9051-508ed1ea9ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1': 0.5762955723975381} {'f1': 0.5766719809382167}\n"
     ]
    }
   ],
   "source": [
    "limpio, limpio_labels = translate_and_eval(labels, pred_limpio)\n",
    "normal, normal_labels = translate_and_eval(labels, pred_normal)\n",
    "print(limpio, normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e983fa3-3141-4b98-a0d5-93d67f41da33",
   "metadata": {},
   "source": [
    "1. Positivo = 2\n",
    "2. Negativo = 0\n",
    "3. Neutral = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0cc4d58-df3b-4e9e-a975-5093aa673ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet mal clasificado: Quiero que alguien me diga cosas bonitas \n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: es el mismo así que tomo nota de todo racias\n",
      "Tag correcto: 2. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: q en horas estemos en septiembre, perdona?????  24 junio dnde stas \n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: Estás muy calladito por aquí julio... q n puedo poner la radio \n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: Hay algunos shojos de comedia romántica que me gustaría que se centraran un poco más en lo romántico \n",
      "Tag correcto: 0. Tag del modelo: 2.\n",
      "---\n",
      "Tweet mal clasificado: Tengo que hacer resumen de sociales de 5 temas y todos los ejercicios de 4 temas  Me suicido ya?\n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "-----------------\n",
      "Tweet mal clasificado: Quiero que alguien me diga cosas bonitas \n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: @IKEASpain es el mismo así que tomo nota de todo  #gracias\n",
      "Tag correcto: 2. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: q en horas estemos en septiembre, perdona?????  24 junio dnde stas \n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: @julioinsadji Estás muy calladito por aquí julio... q n puedo poner la radio \n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n",
      "Tweet mal clasificado: Hay algunos shojos de comedia romántica que me gustaría que se centraran un poco más en lo romántico \n",
      "Tag correcto: 0. Tag del modelo: 2.\n",
      "---\n",
      "Tweet mal clasificado: Tengo que hacer resumen de sociales de 5 temas y todos los ejercicios de 4 temas  Me suicido ya?\n",
      "Tag correcto: 0. Tag del modelo: 1.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def analysis(prediction, reference, dataset):\n",
    "    for i in range(15):\n",
    "        if prediction[i] != reference[i]:\n",
    "            print(f\"Tweet mal clasificado: {dataset['Tweets'][i]}\")\n",
    "            print(f\"Tag correcto: {prediction[i]}. Tag del modelo: {reference[i]}.\")\n",
    "            print(\"---\")\n",
    "            \n",
    "analysis(limpio_labels, pred_limpio, ds_limpio)\n",
    "print(\"-----------------\")\n",
    "analysis(normal_labels, pred_normal, ds_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081e5b8-1904-44db-b550-c861206aeaee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
