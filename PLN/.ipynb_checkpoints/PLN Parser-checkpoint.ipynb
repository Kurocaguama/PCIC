{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37cd9015-7bdd-49c0-bb42-63687ba3383e",
   "metadata": {},
   "source": [
    "## Parsers\n",
    "\n",
    "Esta implementación hace uso de herramientas de nltk y spaCy, y trabaja sobre una Gramática Libre de Contexto personalmente definida. La limitación de esta implementación radica en la dificultad de generalizar un procesamiento arbitrario y no solo dependiente de reglas. Al final del día se termina usando un parser previo proveniente de nltk o de Spacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a4eed54-5cbc-4cdc-b2d0-b9701330c6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('the', 'DT'), ('cat', 'NN'), ('chased', 'VBD'), ('the', 'DT'), ('dog', 'NN')]\n",
      "Árboles:\n",
      "(S (NP (DT the) (NN cat)) (VP (VB chased) (NP (DT the) (NN dog))))\n",
      "              S               \n",
      "      ________|_____           \n",
      "     |              VP        \n",
      "     |         _____|___       \n",
      "     NP       |         NP    \n",
      "  ___|___     |      ___|___   \n",
      " DT      NN   VB    DT      NN\n",
      " |       |    |     |       |  \n",
      "the     cat chased the     dog\n",
      "\n",
      "POS Tags: [('the', 'DT'), ('dog', 'NN'), ('sleeps', 'VBZ'), ('the', 'DT'), ('cat', 'NN'), ('sleeps', 'NNS')]\n",
      "Árboles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\FLopezP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\FLopezP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, CFG\n",
    "from nltk.parse import RecursiveDescentParser\n",
    "\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "def parser_full(sentence):\n",
    "    # Tokenización\n",
    "    tokens = word_tokenize(sentence)\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    print(\"POS Tags:\", pos_tags)\n",
    "    \n",
    "    # Gramática Libre de Contexto\n",
    "    grammar = CFG.fromstring(\"\"\"\n",
    "        S -> NP VP\n",
    "        NP -> DT NN | PRP\n",
    "        VP -> VB NP | VB\n",
    "        DT -> \"the\"\n",
    "        NN -> \"cat\" | \"dog\"\n",
    "        PRP -> \"he\" | \"she\"\n",
    "        VB -> \"chased\" | \"sleeps\"\n",
    "    \"\"\")\n",
    "    \n",
    "    parser = RecursiveDescentParser(grammar)\n",
    "    \n",
    "    # Representación gráfica, cortesía de nltk.\n",
    "    print(\"Árboles:\")\n",
    "    for tree in parser.parse(tokens):\n",
    "        print(tree)\n",
    "        tree.pretty_print()\n",
    "\n",
    "o1 = \"the cat chased the dog\"\n",
    "o3 = \"the dog sleeps the cat sleeps\"\n",
    "parser_full(o1)\n",
    "parser_full(o3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567d89d0-1241-4f42-8e41-742db99a79b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST: [('el', 'DET'), ('gato', 'NOUN'), ('persigue', 'VERB'), ('el', 'DET'), ('perro', 'NOUN')]\n",
      "Árboles:\n",
      "(S (NP (DT el) (NN gato)) (VP (VB persigue) (NP (DT el) (NN perro))))\n",
      "                S                  \n",
      "      __________|______             \n",
      "     |                 VP          \n",
      "     |           ______|___         \n",
      "     NP         |          NP      \n",
      "  ___|___       |       ___|____    \n",
      " DT      NN     VB     DT       NN \n",
      " |       |      |      |        |   \n",
      " el     gato persigue  el     perro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize, CFG\n",
    "from nltk.parse import RecursiveDescentParser\n",
    "import spacy\n",
    "\n",
    "# Se tienen que hacer ciertos ajustes para que funcione en español.\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def parser_es(sentence):\n",
    "    # Tokenización usando spaCy\n",
    "    doc = nlp(sentence)\n",
    "    tokens = [token.text for token in doc]\n",
    "    pos_tags = [(token.text, token.pos_) for token in doc]\n",
    "    print(\"POST:\", pos_tags)\n",
    "    \n",
    "    grammar = CFG.fromstring(\"\"\"\n",
    "        S -> NP VP\n",
    "        NP -> DT NN | PRP\n",
    "        VP -> VB NP | VB\n",
    "        DT -> \"el\" | \"la\"\n",
    "        NN -> \"gato\" | \"perro\"\n",
    "        PRP -> \"él\" | \"ella\"\n",
    "        VB -> \"persigue\" | \"duerme\"\n",
    "    \"\"\")\n",
    "    \n",
    "    parser = RecursiveDescentParser(grammar)\n",
    "    \n",
    "    # Ejemplo visual.\n",
    "    print(\"Árboles:\")\n",
    "    for tree in parser.parse(tokens):\n",
    "        print(tree)\n",
    "        tree.pretty_print()\n",
    "\n",
    "o2 = \"el gato persigue el perro\"\n",
    "parser_es(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a689b774-4ee9-47d7-84aa-eb7d86bea2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST: [('the', 'PROPN'), ('cat', 'PROPN'), ('chased', 'VERB'), ('the', 'PROPN'), ('dog', 'PROPN')]\n",
      "Árboles:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'the', 'cat', 'chased', 'the', 'dog'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ejemplos multilinguales. Claramente no funcionan porque las palabras no están presentes en la CFG del idioma contrario.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mparser_es\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m parser_full(o2)\n",
      "Cell \u001b[1;32mIn[2], line 30\u001b[0m, in \u001b[0;36mparser_es\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Ejemplo visual.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÁrboles:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tree \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(tree)\n\u001b[0;32m     32\u001b[0m     tree\u001b[38;5;241m.\u001b[39mpretty_print()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\nltk\\parse\\recursivedescent.py:76\u001b[0m, in \u001b[0;36mRecursiveDescentParser.parse\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokens):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m# Inherit docs from ParserI\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tokens)\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_grammar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_coverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# Start a recursive descent parse, with an initial tree\u001b[39;00m\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;66;03m# containing just the start symbol.\u001b[39;00m\n\u001b[0;32m     80\u001b[0m     start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grammar\u001b[38;5;241m.\u001b[39mstart()\u001b[38;5;241m.\u001b[39msymbol()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\ayuda_por_favor\\lib\\site-packages\\nltk\\grammar.py:665\u001b[0m, in \u001b[0;36mCFG.check_coverage\u001b[1;34m(self, tokens)\u001b[0m\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[0;32m    664\u001b[0m     missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m missing)\n\u001b[1;32m--> 665\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    666\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrammar does not cover some of the \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput words: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m missing\n\u001b[0;32m    667\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'the', 'cat', 'chased', 'the', 'dog'\"."
     ]
    }
   ],
   "source": [
    "# Ejemplos multilinguales. Claramente no funcionan porque las palabras no están presentes en la CFG del idioma contrario.\n",
    "\n",
    "parser_es(o1)\n",
    "parser_full(o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4c73b-46cf-4004-a7d5-ad1eabe34ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
